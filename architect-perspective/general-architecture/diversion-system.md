# 透明多级分流系统 <Badge text="编写中" type="warning"/>

用户使用信息系统的过程中，请求从浏览器出发，通过网络，触及存储到最后端的数据库服务器中的信息，然后再返回到用户的浏览器，这其中要经过许许多多的技术基础设施。作为系统的设计者，我们应该意识到：不同的设施、部件在系统中有各自不同的价值。它们有一些位于网络的边缘，能够迅速响应用户的请求，避免给后端网络带来压力；有一些易于伸缩拓展，可以使用较小的代价，譬如堆叠机器来获得与用户数量相匹配的处理能力；有一些时刻保持着主从热备，为系统容灾容错，维护着高可用性；但也有一些设施是难以扩展的单点部件，只能依靠堆砌机器本身的性能来提升处理能力，典型的单点部件是传统RDBMS，在事务处理的[CAP部分](transaction.html#cap与acid)中，我们曾讨论过传统数据库为了同时具备可用性和一致性，放弃了分区容错性。

在进行系统设计时，我们应该充分理解这些部件的价值差异，一个普适的原则是尽可能减少单点部件，有一些单点是无可避免的，则应尽最大限度减少到达单点部件的流量。举个例子，许多的用户请求（如获取一张图片）在系统中往往会有多个部件能够处理（如浏览器缓存、CDN、反向代理、Web服务器、文件服务器、数据库都有可能提供这张图片），而恰如其分地将请求分流至最合适的组件中，避免所有流量都汇集到单点（如数据库），同时仍能够（在绝大多数时候）保证处理结果的准确性，仍能在单点系统出现故障时自动而迅速地实施补救措施，这便架构设计中多级分流的原则。缓存、节流、主备、负载均衡等这类措施，都是为了达成该原则所采用的工具与手段，而高可用架构、高并发架构则是通过该原则达成的目标。

一个现代的企业或互联网系统，其中所涉及到的分流手段数量之多、场景之广，可能连它的开发者本身都未必能全部意识到程度。这听起来似乎并不合理，但笔者认为这恰好是优秀架构设计的一种体现，分布广阔谓之“多级”，意识不到谓之“透明”，也就是本章我们要讨论的话题“**透明多级分流系统**”（Transparent Multi-Level Diversion System）的来由。笔者将信息系统中我们可能使用到的分流手段，按从前（用户端）到后（服务端）的顺序列举如下，稍后将逐一讨论：

- **客户端缓存**（Client Cache）：HTTP协议的无状态性决定了它必须依靠客户端缓存来解决网络传输效率上的缺陷。
- **域名解析**（DNS Lookup）：DNS也许是全世界最大、使用最频繁的信息查询系统，如果没有适当的分流机制，DNS将会成为整个网络的瓶颈。
- **链路优化**（Transmission Optimization）：今天的链路优化原则，在若干年后的未来再回头看它们时，其中多数已经成了奇技淫巧，有些甚至成了反模式。
- **内容分发网络**（Content Distribution Network）：CDN是一种十分古老而又透明的分流系统，以至于多出人都说听过它，却没有真正了解过它。
- **负载均衡器**（Load Balancer）：讨论四至七层负载均衡，均衡算法。
- **反向代理**（Reverse Proxy）：讨论反向代理的缓存、动静分离、限流、跨域 、鉴权等方面的应用。
- **Web中间件**（Web/App Server）：讨论数据缓存、方法缓存 / 进程内外、分布式缓存等。
- **数据库服务器**（Database Server）：讨论数据库集群的七层代理，查询缓存，读写分离，链接多路复用等。

## 客户端缓存

::: tip 客户端缓存（Client Cache）

HTTP协议的无状态性决定了它必须依靠客户端缓存来解决网络传输效率上的缺陷。

:::

浏览器的缓存机制几乎是在万维网刚刚出现就已经存在，在HTTP协议设计之初，便确定了服务端与客户端之间“无状态”（Stateless）的交互原则，即要求每次请求是独立的，每次请求无法感知和依赖另一个请求的存在，这既简化了HTTP服务器的设计，也为其水平扩展能力留下了广袤的空间。但无状态并不只有好的一面，由于每次请求都是独立的，服务端不保存此前请求的状态和资源，所以也不可避免地导致其携带有重复的数据，造成网络性能降低。HTTP协议对此的解决方案就是客户端缓存，在HTTP从1.0到最新2.0版本的每次演进中，都提出过现在被称为“状态缓存”、“强制缓存”（许多资料中简称为“强缓存”）和“协商缓存”的缓存机制。

其中，状态缓存是指不经过服务器，客户端直接根据缓存信息对目标网站的状态判断，以前只有301/Moved Permanently（永久重定向）这一个；后来在[RFC6797](https://tools.ietf.org/html/rfc6797)中增加了[HSTS](https://en.wikipedia.org/wiki/HTTP_Strict_Transport_Security)（HTTP Strict Transport Security）机制，用于避免依赖301/302跳转HTTPS时可能产生的降级中间人劫持（详细可见安全架构中的“[传输](system-security.html#传输)”），这也属于另一种状态缓存。由于状态缓存所涉内容就只有这一点，后续我们就只聚焦于强制缓存与协商缓存两种机制。

### 强制缓存

只要是缓存，几乎都不可避免地会遇到一致性的问题。强制缓存对一致性处理就如它的名字一样，显得十分的直接粗暴，假设在某个时间点（譬如10分钟）之内，资源的内容和状态一定不会被改变，因此客户端可以无需经过任何浏览器请求，在该时间点来临前一直持有和使用该资源的本地缓存副本。

根据约定，强制缓存在用户在浏览器输入地址、页面链接跳转、新开窗口、前进/后退中均可生效，但在使用F5刷新页面时应当失效。有以下两类HTTP Header可以实现强缓存：

- **Expires**：Expires是HTTP/1.0协议中提供的Header（当然，在HTTP/1.1中同样存在），后面跟随一个截至时间参数。当服务器返回某个资源时带有该Header的话，意味着服务器承诺截止时间之前资源不会发生变动，浏览器可直接缓存该数据，不再重新发请求，示例：

  ```http
  HTTP/1.1 200 OK
  Expires: Wed, 8 Apr 2020 07:28:00 GMT
  ```
  Expires是HTTP协议最初版本的缓存机制，设计非常直观易懂，但考虑得并不够周全，它至少存在以下显而易见的问题：
  
  - 受限于客户端的本地时间。譬如，客户端修改了本地时间，可能会造成缓存提前失效或超期持有。
  - 无法处理涉及到用户身份的私有资源，譬如，某些资源被登录用户缓存在自己的浏览器上是合理的，但如果被CDN服务器缓存起来，则可能被其他未认证的用户所获取。
  - 无法描述“**不**缓存”的语义。譬如，浏览器为了提高性能，往往会自动在当次会话中缓存某些MINE类型的资源，在HTTP/1.0的服务器中就缺乏手段强制浏览器不允许缓存某个资源。以前为了实现这类功能，通常不得不使用Script脚本，在资源后面增加时间戳（如“xx.js?t=1586359920”）来保证每次资源都会重新获取。<br/>关于“不缓存”的语义，在HTTP/1.0中其实设计了“Pragma: no-cache”来实现，但Pragma在HTTP响应中的行为没有确切描述，随后就被HTTP/1.1中出现过的Cache-Control所替代，现在，尽管主流浏览器通常都会支持Pragma，但实际并没有什么使用价值了。
  
- **Cache-Control**：Cache-Control是HTTP/1.1协议中定义的强制缓存Header，它的语义比起Expires来说就丰富了很多，如果Cache-Control和Expires同时存在，并且语义存在冲突（Expires与max-age / s-maxage冲突）的话，必须以Cache-Control为准。Cache-Control的示例如下：

  ```http
  HTTP/1.1 200 OK
  Cache-Control: max-age=600
  ```

  Cache-Control在客户端的请求头或服务器的响应头中都可以使用，它定义了一系列的参数，且允许扩展（不在标准RFC协议中，由浏览器自行支持），其标准的参数主要包括有：

  - max-age / s-maxage：max-age后面跟随一个以秒为单位的数字，表明相对于请求时间（Date Header中也会注明请求时间），多少秒以内缓存是有效的，资源不需要重新从服务器中获取。相对时间避免了Expires中采用的绝对时间可能受客户端时钟影响的尴尬。s-maxage中的s是“Share”的缩写，意味“共享缓存”（即被CDN、代理等持有的缓存）有效时间，用于提示CDN这类服务器如何对缓存进行失效。
  - public / private：指明是否涉及到用户身份的私有资源，如果是public，着可以被代理、CDN等缓存，如果是private，着只能由客户端进行私有缓存。
  - no-cache / no-store：no-cache指明该资源不应该被缓存，哪怕是同一个会话中对同一个URL地址的请求，也必须从服务端获取（但协商缓存机制依然是生效的）；no-store不强制会话中相同URL资源的重复获取，但禁止浏览器、CDN等以任何形式保存该资源。
  - no-transform：禁止资源被任何形式地修改。譬如，某些CDN、透明代理支持自动GZIP压缩图片或文本，以提升网络性能，而no-transform就禁止了这样的行为，它要求Content-Encoding、Content-Range、Content-Type均不允许进行任何形式的修改。
  - min-fresh / only-if-cached：这两个参数是仅用于客户端的请求Header。min-fresh后续跟随一个以秒为单位的数字，用于建议服务器能返回一个不少于该时间的缓存资源（即包含max-age且不少于min-fresh的数字）。only-if-cached表示要求客户端要求不发送网络请求，只使用缓存来进行响应，若缓存不能命中，就直接返回503/Service Unavailable错误。
  - must-revalidate / proxy-revalidate：must-revalidate表示在资源过期后，一定需要从服务器中进行验证（即超过了max-age的时间，就等同于no-cache的行为），proxy-revalidate用于提示代理、CDN等缓存服务，语义与must-revalidate一致。


### 协商缓存

强制缓存是基于时效性的，但无论是人还是服务器，其实多数情况下都并没有什么把握去承诺某项资源多久不会发生变化。另外一种基于变化检测的缓存机制，在一致性上会有比强制缓存更好的表现，但需要一次变化检测的交互开销，性能上就会略差一些，这种基于检测的缓存机制，通常被称为“协商缓存”。另外，应注意在HTTP中协商缓存与强制缓存并没有排他性，这两套机制是并行工作的，譬如，当强制缓存存在时，直接从强制缓存中返回资源，无需进行变动检查；而当强制缓存超过时效，或者被禁止（no-cache / must-revalidate），协商缓存仍可以正常地工作。协商缓存主要有根据资源的修改时间或根据资源唯一标识是否发生变化来进行变动检查的机制，这都是靠一组成对出现的请求、响应Header来实现的：

- **Last-Modified和If-Modified-Since**：Last-Modified是服务器的响应Header，用于告诉客户端这个资源的最后修改时间。对于带有这个Header的资源，当客户端需要在此请求时，会通过If-Modified-Since把之前收到的资源最后修改时间发送回服务端。<br/>如果此时服务端发现资源在该时间后没有被修改过，就只要返回一个304/Not Modified的响应即可，无需附带消息体，如下所示：

  ```http
  HTTP/1.1 304 Not Modified
  Cache-Control: public, max-age=600
  Last-Modified: Wed, 8 Apr 2020 15:31:30 GMT
  ```

  如果此时服务端发现资源在该时间之后有变动，就会返回200/OK的完整响应，在消息体中包含最新的资源，如下所示：

  ```http
  HTTP/1.1 200 OK
  Cache-Control: public, max-age=600
  Last-Modified: Wed, 8 Apr 2020 15:31:30 GMT
  
  Content
  ```

- **Etag和If-None-Match**：Etag是服务器的响应Header，用于告诉客户端这个资源的唯一标识（HTTP服务器可以根据自己的意愿来选择如何生成这个标识，譬如Apache服务器的Etag值，默认是对文件的索引节点（INode），大小（Size）和最后修改时间（MTime）进行哈希计算后得到的），对于带有这个Header的资源，当客户端需要在此请求时，会通过If-None-Match把之前收到的资源唯一标识发送回服务端。<br/>如果此时服务端计算后发现资源的唯一标识与上传回来的一致，说明资源没有被修改过，就只要返回一个304/Not Modified的响应即可，无需附带消息体，如下所示：

  ```http
  HTTP/1.1 304 Not Modified
  Cache-Control: public, max-age=600
  Last-Modified: Wed, 8 Apr 2020 15:31:30 GMT
  ```

  如果此时服务端发现资源的唯一标识有变动，就会返回200/OK的完整响应，在消息体中包含最新的资源，如下所示：

  ``` http
  HTTP/1.1 200 OK
  Cache-Control: public, max-age=600
  Last-Modified: Wed, 8 Apr 2020 15:31:30 GMT
  
  Content
  ```

Etag是HTTP中一致性最强的缓存机制，譬如，Last-Modified标注的最后修改只能精确到秒级，如果某些文件在1秒钟以内，被修改多次的话，它将不能准确标注文件的修改时间；又或者如果某些文件会被定期生成，可能内容并没有任何变化，但Last-Modified却改变了，导致文件无法有效使用缓存，这些情况Last-Modified都有可能产生一致性问题，只能使用Etag解决。

Etag却又是HTTP中性能最差的缓存机制，体现在每次请求时，服务端都必须对资源进行哈希计算，这比起简单获取一下修改时间，开销要大了很多。Etag和Last-Modified是允许一起使用的，服务器会优先验证Etag，在Etag一致的情况下，再去对比Last-Modified，这是为了防止有一些HTTP服务器未将文件修改日期纳入哈希范围内。

到这里为止，HTTP的协商缓存机制已经能很好地处理通过URL获取**单个资源**的场景，“单个资源”是什么意思？在HTTP协议的设计中，一个URL地址有可能能够提供多份不同版本的资源，譬如，一段文字的不同语言版本，一个文件的不同编码格式版本，一份数据的不同压缩方式版本，等等。HTTP协议设计了Accept\*（Accept、Accept-Language、Accept-Charset、Accept-Encoding）的一套请求Header和对应的Content-\*（Content-Language、Content-Type、Content-Encoding）的响应Header，这被称为HTTP的内容协商机制。与之对应的，对于一个URL能够获取多个资源的场景中，缓存也同样也需要有明确的标识来获知根据什么内容来对同一个URL返回给用户正确的资源。这个就是Vary Header的作用，Vary后面可以跟随其他Header的名字，譬如：

```http
HTTP/1.1 200 OK
Vary: Accept, User-Agent
```

以上说明应该根据MINE类型和浏览器类型来缓存资源，获取资源时也需要根据请求头中对应的字段来筛选出适合的资源版本。

根据约定，协商缓存不仅在用户在浏览器输入地址、页面链接跳转、新开窗口、前进/后退中生效，而且在使用F5刷新页面时也同样是生效的，只有用户强制刷新（Ctrl+F5）或者禁用缓存（譬如在DevTools中设定）时才会失效，此时客户端向服务端发出的请求会自动带有“Cache-Control: no-cache”。

## 域名解析

::: tip 域名缓存（DNS Lookup）

DNS也许是全世界最大、使用最频繁的信息查询系统，如果没有适当的分流机制，DNS将会成为整个网络的瓶颈。

:::

我们都知道DNS的作用是将便于人类理解的域名地址转换为便于计算机处理的IP地址，也许你会觉得好笑：笔者在接触计算机网络的开头一段不短的时间里面，都把DNS想像成一个部署在全世界某个神秘机房中的大型电话本式的翻译服务。后来，当笔者第一次了解到DNS的工作原理，并知世界根域名服务器的ZONE文件只有2MB大小（甚至可以打印出来物理备份）的时候，对DNS系统的设计是非常惊讶的。域名解析这个话题同样涉及缓存等因素，虽然它并不算本篇讨论的重点，但其本身就是堪称示范性的透明多级分流系统，很值得我们借鉴。

假设我们访问域名：www.icyfenix.com.cn，DNS并不是一次性地将“www.icyfenix.com.cn”解析成IP地址的，这需要经历一个递归解析的过程。首先DNS会将域名还原为“www.icyfenix.com.cn.”，注意最后多了一个点“.”，它是“.root”的含义（早期的域名必须带有这个点DNS才能够正确解析，如今DNS服务器已经可以自动补上结尾的点号），然后开始如下过程：

1. 客户端检查本地DNS缓存，查看是否存在并存活着的该域名的地址记录，DNS是以[存活时间](https://zh.wikipedia.org/zh-tw/%E5%AD%98%E6%B4%BB%E6%99%82%E9%96%93)（Time to Live，TTL）来衡量缓存的存活情况的。后续每一级DNS查询的过程都会有类似的缓存查询操作，将不再重复叙述。
2. 客户端将地址发送给本机系统中设置的本地DNS（Local DNS，这个服务器可以通过手工设置，在路由做DHCP分配时或者在拨号时从PPP服务器中也会自动获取到）。
3. 本地DNS收到查询后，会按照“是否有www.icyfenix.com.cn的权威服务器”-->“是否有icyfenix.com.cn的权威服务器”-->“是否有com.cn的权威服务器”-->“是否有cn的权威服务器”的顺序，查询自己的地址记录，如果都没有查询到，就会一直找到最后点号代表的根域名服务器为止。这里涉及了两个名词：
   - **权威域名服务器**是指能够翻译指定域名的DNS服务器。
   - **根域名服务器**是指无需查询的、默认已内置的[顶级域名](https://en.wikipedia.org/wiki/Top-level_domain)（Top-Level Domain）服务器。全世界一共有13个根域名服务器（但并不是13台，每一个根域名都通过任播的方式建立了一大群镜像，根据维基百科的数据，迄今已经超过1000台根域名服务器的镜像了）。13这个数字是由于DNS主要采用UDP传输协议（在需要稳定性保证的时候也可以采用TCP）来进行数据交换，未分片的UDP数据包在IPv4下最大有效值为512字节，由此而来的限制。
4. 我们假设本地DNS是新开张的，上述权威服务器的记录它都没有，一直查到根域名服务器后，它将会得到“cn的权威服务器”的记录，然后通过“cn的权威服务器”，得到“com.cn的权威服务器”，以此类推，最后找到“www.icyfenix.com.cn的权威服务器”。
5. 通过“www.icyfenix.com.cn的权威服务器”，查询www.icyfenix.com.cn的地址记录（有RFC定义的地址记录有[数十种类型](https://zh.wikipedia.org/wiki/DNS%E8%AE%B0%E5%BD%95%E7%B1%BB%E5%9E%8B%E5%88%97%E8%A1%A8)，譬如IPv4下的IP地址为A记录，IPv6下的AAAA记录、主机别名CNAME记录，等等），选择一条合适的返回给客户端。

一个域名可以配置多条不同的A记录，此时权威服务器可以根据自己的策略来进行选择。一种典型的应用是智能线路：根据访问者所处的不同地区（譬如华北、华南、东北、港澳台、国外）、不同服务商（譬如电信、联通、移动）等因素来确定返回的A记录。

DNS系统多级分流的设计使得DNS系统能够经受住全球网络流量不间断的冲击，但也并非全无缺点。譬如，当极端情况（各级服务器均无缓存）下的域名解析可能导致后续递归的多次查询而显著影响响应速度，譬如下图所示。

:::center
![](./images/dns-lag.png)
首次DNS请求耗时（图片来自网络）
:::

专门有一种被称为“DNS预取”（DNS Prefetching）的前端优化手段：如果网站后续要使用来自于其他域的资源，那就在网页加载时便生成一个link请求，促使浏览器对该域名进行预解释，譬如下面所示：

```html
<link rel="dns-prefetch" href="//domain.not-icyfenx.cn">  
```

而另一种可能更严重的缺陷是DNS的分级查询意味着每一级都有可能受到中间人攻击的威胁，产生被劫持的风险。要攻陷位于递归链条顶层的（譬如根域名服务器，cn权威服务器）服务器和链路是非常困难的，但很多位于递归链底层的、本地运营商的Local DNS服务器的安全防护则相对松懈，甚至不少地区的运行商自己就会进行劫持，专门返回一个错的IP，在这个IP上代理用户请求，以便给特定资源（主要是HTML）注入广告，以此牟利。

为此，最近几年出现了另一种新的DNS应用形式：[HTTPDNS](https://en.wikipedia.org/wiki/DNS_over_HTTPS)（也称为DNS over HTTPS，DoH）。它将DNS服务开放为一个HTTPS服务，替代基于UDP传输协议的DNS域名解析，直接从权威DNS或者可靠Local DNS获取解析数据，从而绕过传统Local DNS。这种做法的好处是避免了底层的域名劫持（遇到顶层劫持是往往是政府行为，这是没办法的），能够有效解决Local DNS不可靠导致的域名生效缓慢、来源IP不准确产生的智能线路切换错误等问题。

## 链路优化

::: tip 链路优化（Transmission Optimization）

今天的链路优化原则，在若干年后的未来再回头看它们时，其中多数已经成了奇技淫巧，有些甚至成了[反模式](https://zh.wikipedia.org/wiki/%E5%8F%8D%E9%9D%A2%E6%A8%A1%E5%BC%8F)。

:::

在开始本节的讨论前，笔者先列一些在网络上很容易就能找到的，对Web进行链路性能优化的原则（譬如[雅虎YSlow23条规则](https://developer.yahoo.com/performance/rules.html)），这些原则在今天大多仍是（暂时）有一定价值的，至少也算是曾经（可能现在也还算是）广泛地流行过，但大概率在若干年后的未来再回头看它们时，其中多数已经成了奇技淫巧，有些甚至成了反模式。趁着当今的Web在传输链路这一块正处于新老交替之际，我们来说一下两代HTTP协议下的链路优化的问题。

1. 利用客户端缓存：缓存总是有益的，这点第一节中详细介绍过，本节不再涉及。
2. 减少请求数量：请求每次都需要建立通信链路进行数据传输，这些开销很昂贵，减少请求的数量可有效的提高访问性能。
	- 雪碧图（[CSS Sprites](https://en.wikipedia.org/w/index.php?title=CSS_Sprites&redirect=no)）
	- CSS、JS文件合并/内联（Concatenation / Inline）
	- 分段文档（[Multipart Document](https://www.w3.org/Protocols/rfc1341/7_2_Multipart.html)）
	- 媒体（图片、音频）内联（[Data Base64 URI](https://en.wikipedia.org/wiki/Data_URI_scheme)）
	- 异步请求合并（Batch Ajax Request）
	- ……
3. 扩大并发请求数：现代浏览器一般对每个域名支持6个（IE为8-13个）并发请求，如果希望更快地加载大量图片或其他资源，需要进行域名分片（Domain Sharding），将图片同步到不同主机或者同一个主机的不同域名上（YSlow：Split Components Across Domains）。
4. 避免页面重定向：当页面发生了重定向，就会延迟整个文档的传输。在HTML文档到达之前，页面中不会呈现任何东西，降低了用户体验。
5. 按重要性调节资源优先级：将重要的、马上就要使用的、对客户端展示影响大的资源，放在HTML的头部，以便优先下载。
6. 启用压缩传输：启用压缩能够大幅度减少需要在网络上传输内容的大小，节省网络流量。
7. …………

如同之前介绍客户端缓存时提到的那样，HTTP要得到无状态的好处，就必须相应承受网络效率降低的代价。在其他方面，HTTP协议设计和应用中也经历过了类似的权衡取舍，现在看来那些需要用户去优化的内容，往往都是当时技术现状下权衡取舍的结果。我们就从优化原则中条目最多的针对HTTP请求数量的措施说起。

### 连接数优化

我们都知道HTTP是基于TCP协议的，必须在[TCP三次握手](https://zh.wikipedia.org/wiki/%E4%BC%A0%E8%BE%93%E6%8E%A7%E5%88%B6%E5%8D%8F%E8%AE%AE#建立通路)完成之后才能进行数据传输，这是一个通常以“百毫秒”为计时尺度的事件；此外，TCP还有[慢启动](https://zh.wikipedia.org/wiki/%E6%85%A2%E5%90%AF%E5%8A%A8)的特性，使得刚刚建立连接时传输速度是最低的，后面再逐步加快直至稳定。由于TCP协议本身是面向于长时间、大数据传输来设计的，在长时间尺度下，它连接建立的成本高昂才不至于成为瓶颈，它的稳定性和可靠性的优势才能展现出来，那显然HTTP over TCP这种搭配，在目标倾向上就多少产生了一些矛盾，以至于HTTP/1.x时代，大量短而小的TCP连接确实造成了网络性能的瓶颈。为了缓解HTTP在这个问题上的缺陷，聪明的程序员们一面致力于减少发出的请求数量，另外一方面也致力于增加客户端到服务端的连接数量，就是上面2、3点所提到的优化措施。这些Tricks的确减少消耗TCP连接数量，下面两张图片是来自于[HTTP Archive](https://httparchive.org/)对最近五年来数百万个URL地址采样得出的结论，页面平均请求没有改变的情况下，TCP连接在持续地下降（当然，后面说的HTTP/2.0其实占了很大功劳）。

:::center
![](./images/http-req.png)
HTTP平均请求数量，70余个，没有明显变化

![](./images/tcp-conn.png)
TCP连接数量，约15个，有明显下降趋势
:::

但是，上述这些节省TCP连接的优化措施但也带来了诸多不良的副作用：

- 如果你用CSS Sprites将多张图片合并，意味着任何场景下哪怕只用到其中一张小图，也必须完整加载整个大图片；任何场景下哪怕一张小图要进行修改，都会导致整个缓存失效，类似地，样式、脚本等其他文件的合并也会造成同样的问题。
- 如果你使用了媒体内嵌，除了要承受Base64编码导致提及膨胀1/3的代价外，也将无法有效利用缓存。
- 如果你合并了异步请求，这就会导致所有请求返回时间都受最慢的那个请求的拖累，整体响应速度下降.
- 如果你把图片放到不同子域下面，将会导致更大的DNS解析负担，而且浏览器对两个不同子域下的同一图片必须持有两份缓存，也使得缓存效率的下降。
- ……

由此可见，一旦技术根基上出现的缺陷，依赖使用者通过各种Tricks去解决，无论如何都难以摆脱“两害相权取其轻”的权衡困境，否则这就不是Tricks而是会成为一种标准的设计模式了。

在另一方面，HTTP的设计者们并非没有尝试过在基础设施层面去解决连接成本过高的问题，即使是HTTP协议的最初版本（指HTTP/1.0，忽略非正式的HTTP/0.9版本）也是支持（不是默认，HTTP/1.1中变为默认）连接复用的，即今天大家所熟知的[持久连接](https://zh.wikipedia.org/wiki/HTTP%E6%8C%81%E4%B9%85%E8%BF%9E%E6%8E%A5)（Persistent Connection）或者叫连接[Keep-Alive机制](https://zh.wikipedia.org/wiki/Keepalive)。其大致原理是让客户端可以对一个域名长期持有一个（或多个）TCP连接，在客户端维护一个FIFO队列，每次取完数据（如何在不断开连接下判断取完数据将会放到稍后压缩部分去讨论）之后不断开连接，以便下一个资源需要获取时备用，避免创建TCP连接的成本。而在2014年，IETF发布的[RFC 7230](https://tools.ietf.org/html/rfc7230#section-6.3.2)中提出了名为“[HTTP管道]([https://zh.wikipedia.org/wiki/HTTP%E7%AE%A1%E7%B7%9A%E5%8C%96](https://zh.wikipedia.org/wiki/HTTP管線化))”（HTTP Pipelining）复用技术试图在服务端也建立类似的队列，以进一步提高效率，客户端一次过将所有请求发给服务端，由服务端来管理队列的话，可以保证队列中两项工作之间没有空隙，甚至可能进行并行化处理，提升了服务端的效率。不过，HTTP管道需要多方共同支持，推广得并不算成功。

不幸的是，连接复用仍然存在它的副作用，最主要的一项副作用是“[队首阻塞](https://zh.wikipedia.org/wiki/%E9%98%9F%E5%A4%B4%E9%98%BB%E5%A1%9E)”（Head-of-Line Blocking）问题，请设想以下场景：浏览器有10个资源需要从服务器中获取，此时它将10个资源放入队列，入列顺序只能是按照浏览器预见这些资源的先后顺序来决定的。但如果这10个资源中的第1个就让服务器陷入长时间运算状态那会怎样？当它的请求被发送到服务端之后，服务端开始计算，而运算结果出来之前TCP连接中并没有任何数据返回，此时后面9个资源都必须阻塞等待。无论队列维护在服务端还是客户端，其实都无法解决这个问题，因为服务端虽然很可能可以并行处理另外9个请求（譬如第1个是复杂运算请求，消耗CPU资源，第2个是数据库访问，消耗数据库资源，第3个是访问某张图片，消耗磁盘IO资源，等等，这就很适合并行），但处理结果却无法发回给客户端，服务端既不能哪个请求先完成就返回哪个，更不可能将所有要返回的资源混杂到一起交叉传输……显然，TCP连接带来的问题，本质上是传输链路上的问题，无论在服务端还是客户端，涉及到传输方面都显得无能为力。

队首阻塞问题一直持续到第二代的HTTP协议，即HTTP/2.0发布后才算是被比较完美地解决。在HTTP/1.x中，“请求”就是传输过程中最小粒度的信息单位了，所以如果将多个请求切碎，再混杂在一块传输，客户端势必难以分辨重组出有效信息。而在HTTP/2.0中，帧（Frame）才是最小粒度的信息单位，它可以用来描述各种数据，譬如请求的Header、Body，或者用来做控制标识，譬如打开流、关闭流。这里说的流（Stream）是一个逻辑数据通道的概念，每个帧都附带有一个流ID以标识这个帧属于哪个流。这样，在同一个TCP连接中传输的多个数据帧就可以根据流ID轻易区分出开来，在客户端毫不费力地将不同流中的数据重组出HTTP的请求、响应报文来。这项设计是HTTP/2.0的重点技术特征之一，被称为[HTTP/2.0 多路复用](https://tools.ietf.org/html/rfc7540#page-15)（HTTP/2.0 Multiplexing）

:::center
![](./images/http2-con.png)
HTTP2的多路复用（图片来自：[https://hpbn.co/http2](https://hpbn.co/http2)）
:::

有了多路复用的支持，HTTP/2.0就可以对每个域名只维持一个TCP连接（One Connection Per Origin），既减轻了服务器的连接压力，开发者也不用去考虑域名分片这种事情来突破浏览器对每个域名最多6个连接数限制了。而更重要的是，没有了TCP连接数的逼迫，所有通过合并/内联文件（无论是图片、样式、脚本）以减少请求数的需求就不再成立了，甚至反而是徒增副作用的反模式了——可能还有人会反驳说：不至于吧，减少请求数量，不是至少还减少了传输中耗费的Header吗？先得承认一个事实，在HTTP协议中，Header的成本所占的比重相当的大，以至于在HTTP/2.0中需要专门考虑如何进行Header压缩的问题。但是，以下几个因素导致了通过合并资源文件减少请求数，对节省Header成本也几乎没有帮助：

- Header的传输成本在Ajax（尤其是只返回少量数据的请求）请求中可能是比重很大的开销，但在图片、样式、脚本这些静态资源的请求中，通常并不占主要。
- 在HTTP/2.0中Header压缩的原理是基于字典编码的信息复用，简而言之是同一个连接上产生的请求和响应越多，动态字典积累得越全，头部压缩效果也就越好。所以HTTP/2.0是单域名单连接的机制，合并资源和域名分片反而对性能提升不利。
- 与HTTP/1.x相反，HTTP/2.0本身反而变得更适合传输小资源了，譬如传输1000张10K的小图，HTTP/2.0要比HTTP/1.x快，但传输10张1000K的大图，则应该HTTP/1.x会更快。这一方面是TCP连接数量（相当于多点下载）的影响，更多的是由于TCP协议丢包重传机制导致的，一个丢失的TCP包会导致所有的流都必须等待这个包重传成功，这个问题就是HTTP/3.0要解决的目标了。因此，把小文件合并成大文件，在HTTP/2.0下是毫无好处的。

### 传输压缩

我们接下来再花一点点篇幅来讨论链路优化中除了缓存、连接之外另一个主要话题：压缩。很多人都知道HTTP协议是支持[GZip](https://zh.wikipedia.org/wiki/Gzip)压缩的，由于HTTP传输的主要内容，譬如HTML、CSS、Script等，都是文本数据，对于这些文本数据启用压缩的收益是非常高的，传输量一般会降至原有的20%左右。而对于那些不适合压缩的资源，Web服务器则能根据MINE类型来自动判断是否对响应进行压缩，这样，已经采用过压缩算法存储的资源，如JPEG、PNG图片，便不会被二次压缩，空耗性能。

不过，大概就没有多少人想过压缩与之前提到的用于节约TCP的持久连接机制是存在一些冲突的。在古代，服务器处理能力还很差的时候，通常是把静态资源先预先压缩为.gz文件的形式存放起来，当客户端可以接受压缩版本的资源时（请求的Header中包含Accept-Encoding: gzip）就返回压缩后的版本（响应的Header中包含Content-Encoding: gzip），否则就返回未压缩的原版，这种方式被称为“[静态预压缩](http://nginx.org/en/docs/http/ngx_http_gzip_static_module.html)”（Static Pre-compression）。而现代的Web服务器处理能力有了大幅提升，已经没有人再采用麻烦的预压缩方式了，都是由服务器对符合条件的请求将在输出时进行“[即时压缩](https://www.usenix.org/legacy/publications/library/proceedings/jvm01/full_papers/hovemeyer/hovemeyer_html/node7.html)”（On-The-Fly Compression），整个压缩过程全部在内存的数据流中完成，不必等资源压缩完成再返回响应，这样可以显著提高“[首字节时间](https://en.wikipedia.org/wiki/Time_to_first_byte)”（Time To First Byte，TTFB），改善Web性能体验。而这个过程中唯一不好的地方就是服务器再没有办法给出Content-Length这个响应Header了，因为输出Header时服务器还不知道压缩后资源的确切大小。

到这里，大家想明白即时压缩与持久链接的冲突在哪了吗？持久链接机制不再依靠TCP连接是否关闭来判断资源请求是否结束，它会重用同一个连接以便向同一个域名请求多个资源，这样，客户端就必须要有除了关闭连接之外的其他机制来判断一个资源什么时候算传递完毕，这个机制最初（在HTTP/1.0时）就只有Content-Length，即靠着请求头中明确给出资源的长度，传输到达该长度即宣告一个请求响应的结束。由于启用即时压缩后就无法给出Content-Length了，如果是HTTP/1.0的话，持久链接和即时压缩只能二选其一（HTTP/1.0中两者默认都是不开启的）。其实Content-Length的缺陷不仅仅在于即时压缩这一种场景，譬如对于动态内容（Ajax、PHP、JSP等输出），服务器也同样无法事项得知Content-Length。

HTTP/1.1版本中修复了这个缺陷，增加了另一种“[分块传输编码](https://zh.wikipedia.org/wiki/%E5%88%86%E5%9D%97%E4%BC%A0%E8%BE%93%E7%BC%96%E7%A0%81)”（Chunked Transfer Encoding）的资源结束判断机制，解决Content-Length与持久链接的冲突问题。分块编码原理相当简单：在响应Header中加入“Transfer-Encoding: chunked”之后，就代表这个响应报文将采用分块编码。此时，报文中的Body需要改为用一系列“分块”来传输。每个分块包含十六进制的长度值和对应长度的数据内容，长度值独占一行，数据从下一行开始。最后以一个长度值为0的分块来表示资源结束。举个例子（来自于前面维基百科中的页面，为便于观察，只分块，未压缩）：

```http
HTTP/1.1 200 OK
Date: Sat, 11 Apr 2020 04:44:00 GMT
Transfer-Encoding: chunked
Connection: keep-alive

25
This is the data in the first chunk

1C
and this is the second one

3
con

8
sequence

0
```

根据分块长度可知，前两个分块包含显式的回车换行符（CRLF，即\r\n字符）

```txt
"This is the data in the first chunk\r\n"      (37 字符 => 十六进制: 0x25)
"and this is the second one\r\n"               (28 字符 => 十六进制: 0x1C)
"con"                                          (3  字符 => 十六进制: 0x03)
"sequence"                                     (8  字符 => 十六进制: 0x08)
```

所以解码后的内容为：

```txt
This is the data in the first chunk
and this is the second one
consequence
```

一般来说，Web服务器给出的数据分块大小是一致的（但并不强制），而不是如例子中那样随意。HTTP/1.1通过分块传输解决了即时压缩与持久连接并存的问题，到了HTTP/2.0，由于多路复用和单域名单连接的设计，已经无需再刻意强去提久链接机制了，但数据压缩仍然有节约传输带宽的重要价值。

## 内容分发网络

::: tip 内容分发网络（Content Distribution Network）

CDN是一种十分古老而又透明的分流系统，以至于多出人都说听过它，却没有真正了解过它。

:::

前面几个小节介绍了缓存、域名解析、链路优化，这节我们来讨论它们的一个经典的综合运用案例：内容分发网络（Content Distribution Network，CDN）。

CDN是一种十分古老的应用，以至于笔者相信阅读此文的受众至少有八、九成应该对它有不同程度的了解的——起码是听说过它的。如果把某个互联网系统比喻为一家开门营业的企业，那CDN就是它遍布世界各地的分支销售机构，客户要买一块CPU就订机票飞到美国加州Intel总部去那肯定是不合适的，去到本地电脑城找个装机铺才像个正常人类的做法，CDN就相当于电脑城那吆喝着CPU三十块钱一斤的本地经销商。

CDN又是一种十分透明的应用，以至于笔者相信阅读此文的受众至少有八、九成应该对它是如何为自己系统分流、对它的工作原理并没有什么系统性的概念——起码没有自己亲自使用过。如果抛却其他影响服务质量的因素，仅从网络角度看，一个互联网系统的速度好坏取决于：

1. 网站服务器接入网络运营商的链路所能提供的出口带宽。
2. 用户客户端接入网络运营商的链路所能提供的入口带宽。
3. 从网站到用户之间经过的不同运营商之间互联节点的带宽，一般来说两个运营商之间只有固定的若干个点是互通的，所有跨运营商之间的交互都要经过这些点。
4. 从网站到用户之间的物理链路传输时延。打游戏的同学都清楚，ping很重要。

以上四个网络问题，除了第二个只能由用户掏腰包装个更好的宽带才能够处理之外，其余三个都是通过内容分发网络来解决的。一个工作良好的CDN，能为互联网系统解决跨运营商、跨地域物理距离所导致的时延问题，能为网站起到分流、减负的作用。如果不是有遍布全国的阿里云CDN网络支持，哪怕把整个杭州所有市民上网的权力都剥夺，带宽全部让给淘宝，恐怕也撑不住双十一全国乃至全球用户的疯狂围攻。

CDN的工作过程，主要涉及到路由解析、内容分发、负载均衡和所能支持的缓存内容四个方面，下面我们来逐一了解。

### 路由解析

根据我们在第二节中对DNS系统的介绍，一个用户访问网站（未使用CDN）的过程应该是这样的：

<mermaid style="margin-bottom: 0px">
graph LR
    Start --> Stop
</mermaid>



### 内容分发



### 负载均衡



### 缓存支持